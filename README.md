# fairBench-tiny

*Fairness metrics at wire speed.*

This is a high-performance C utility for evaluating basic fairness metrics from large tabular datasets.  

It provides a lightweight alternative to the [**FairBench**](https://github.com/mever-team/FairBench) Python framework for bias and fairness assessment. This variation is ideal for environments where speed and memory efficiency are critical by streaming through a file and accumulating values without loading all data in memory.

## üî• Features

- Fast parsing of large CSV/TSV files with bare metal code.  
- Aggregate group-wise metrics for classification (tpr, tnr, accuracy, pr).
- Color-coded output and exit codes for failing analysis. 
- Minimal energy footprint in a few kB of memory - set up as a worker.
- Expressive arguments that can be read from *.fb* scripts to revisit complicated analysis.
- Streaming interface.

**Intentional limitations** 

When the assumptions below are violated, *fbt* will exit with error code 2. All can be addressed given adequate interest, but they are chosen for fast implementation that addresses many realistic scenarios.

- Each cell must comprise up to 127 characters. This is a constant in *src/data.h* that you can change and recompile.
- File lines are assumed to span up to 4kB. This is also a constant in *src/data.h*.
- Up to 64 cols can be analyzed. This is also a constant in *src/data.h*.
- The employed hashing algorithm for categorical column values may consume much more memory than expected (still in the order of magnitude of some kBs at most). This algorithm is chosen for the sake of speed, so there is a soft (and unknown) upper limit
on the number of different categorical attribute values that can occur - ideally these should be less than 80.

## ‚ö° Quickstart

Download the *./fbt* executable from the project's 
[latest release](https://github.com/maniospas/fairbench-tiny/releases/latest).
If you have an issue, want to contribute, or your platform is not supported, clone this repository and run `make`. This will create the executable `build/fbt`.

Run the executable:

```bash
./fbt data.csv [--label colname] [--predict colname] [--threshold value] [--members min_count]
```

- data.csv Path to the CSV/TSV data file to analyze. If no path is provided, *fbt* polls stdin every 100ms to provide live updates.
- --label &lt;colname> Name of the column containing true labels (default: *label*).
- --predict &lt;colname> Name of the column containing predicted labels (default: *predict*).
- --threshold &lt;value> Highlight values below this fairness threshold in red, and above 1-threshold in green (default: 0.0). Violated thresholds make the final report return with exit code 1.
- --numbers &lt;value> Declares that numerical data columns with less than the number of distinct values should be treated as categorical. For example, you might have values 1,2,3 for marital status, where the identifiers are explained elsewhere.
- --members &lt;min_count> Minimum number of samples required for a group to be included in the fairness report. Groups with fewer members are ignored.
- --stream &lt;rows> Stream an update after every fixed number of seconds. If this is set and no path is provided, you get live
updates from *stdin*.
- --forget &lt;rate> Sets a forget rate in the range `(0,1]` that degrades the importance of earlier samples. Its value should be small (e.g., 0.01 or much smaller). Particularly useful when streaming over time.
- @&lt;NAME> Switches to declaring column-specific characteristics. These are presented next.
- --numerical Indicates that the column holds numerical data (this is prioritized over the globally set --numbers).
- --skip Ignores the column during parsing.

## üìù Script files

You might have complex arguments in your run that would be a shame to lose.
In those cases, pass as the only argument a configuration *.fb* file like the ones in *examples/*. 
Scripts can be accompanied by command line arguments, but this behavior is not 
well-defined right now in case of conflicts - you will either see an error or the command line
arguments are overwritten, and this behavior will likely change in the future.

Run script files like below:

```bash
./fbt examples/credit.fb
```

Here is an example script, where code highlighting comes from a VScode extension (look for fairbench).
The outcome reports only on the columns of interest.

<div style="display: flex; justify-content: center; gap: 1rem; flex-wrap: wrap;">
  <figure style="text-align: center;">
    <img src="examples/fbt_script.png" alt="Example Script" width="400" style="border-radius: 8px;"><br>
    <figcaption>Example script (shown by the <i>FairBench Tiny Syntax</i> extension in VSCode)</figcaption>
  </figure>
  <br>
  <figure style="text-align: center;">
    <img src="examples/fbt_results.png" alt="Outcome Report" width="400" style="border-radius: 8px;"><br>
    <figcaption>Outcome fairness report generated by the script</figcaption>
  </figure>
</div>


## üìò Expected input

The first data line must contain column headers (group names, *label*, and *predict*). Columns may be separated by **comma `,`**, **tab `\t`**, or **semicolon `;`** ‚Äî the first of those delimiters that is encountered is used from thereon.
**Whitespace** or quotations `"` are ignored everywhere.  

All rows must have the same number of columns as the header, and must contain categorical or numerical data values at every column. For predictions and labels, if no column specifications are provided, values are considered binary identified by whether column entries start with *y*, *Y*, or *1*.

```csv
gender,region,label,predict
1,0,1,1
0,0,0,0
1,1,1,0
0,1,0,1
```

## ‚ú® Streaming interface

You can monitor running algorithms by flushing predictions to the executable's *stdin*. For example, in Linux you can pipe the *stdout* of a Python process like below. The example uses a Python script that emulates an algorithm outputting results.

```python
# examples/streamer.py
import time
import sys
import random

# --- Write header ---
sys.stdout.write("gender,region,label,predict\n")
sys.stdout.flush()

while True:
    gender = random.choice(["man", "woman", "other"])
    region = random.choice(["here", "there", "everywhere", "nowhere"])
    label = random.choice(["0", "1"])
    predict = random.choice(["0", "1"])
    sys.stdout.write(f"{gender},{region},{label},{predict}\n")

    if random.random() < 0.05:
        sys.stdout.flush() # randomly flush for demonstration
    time.sleep(0.01) # mimics a slow algorithm (not needed)
```

```bash
python3 examples/streamer.py | ./fbt --stream 1
```


## üß™ Benchmarks

Benchmarks are lies. But they are useful lies. So here is a comparison using the *perf* tool on a Linux machine
to repeat a credit dataset analysis 10 times for consistency. Approximate ranges of consumed resources are reported for the task of computing 
absolute positive rate differences between two sexes on the *Credit* dataset. This is done using AIF360 (a very popular fairness analysis library), FairBench, and FairBench-tiny. 

Honestly, there is not much to expect from a comparison of an interpreted vs a compiled framework; the latter will always dominate. But below is a validation of this common engineering truth anyway. Python 3.13.1 is used everywhere.

| Framework | Runtime (sec) | Energy (Joules) | Memory (MB) |
|------------|--------------|-------------|--------------|
| **Pandas + AIF360** | 0.72‚Äì0.80 | 27.23 | <170 | 
| **Pandas + FairBench** | 0.35‚Äì0.36 | 12‚Äì13 | <98 | 
| **FairBench-tiny** | **0.01‚Äì0.03** | **0.4‚Äì0.8** | **<2** | 

Python libraries cannot be decoupled from their interpreter in this use case of analyzing a dataset (and potentially predictions) stored in disk. So the above numbers include interpreter startup and dataset loading overheads that consume 0.33‚Äì0.36 sec and 12‚Äì14 Joules. If these are ignored, FairBench's internal NumPy usage (which wraps compiled code) ends up also being lightweight.

While acknowledging that huge gains are pretty normal when comparing Python vs C implementations, FairBench-tiny achieves:

- 17+ lower energy consumption compared to the other frameworks.
- 30‚Äì80x faster execution.  
- ~50x lower memory usage. Because the input file is streamed instead of being read completely first. This is the greatest gain from an engineering standpoint. 

Commands for transparency and future replicability:

```bash
make
sudo perf stat -e power/energy-pkg/ build/fbt examples/credit.fb
/usr/bin/time -v build/fbt examples/credit.fb
```